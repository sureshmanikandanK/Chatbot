{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      3\u001b[0m load_dotenv()\n\u001b[1;32m----> 5\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGROQ_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGROQ_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<frozen os>:719\u001b[0m, in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n",
      "File \u001b[1;32m<frozen os>:779\u001b[0m, in \u001b[0;36mcheck_str\u001b[1;34m(value)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['\"GROQ_API_KEY\"'] = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000020CB0D8E9E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020CB0D8D750>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Ajith, \\n\\nThat's awesome! It's great to meet another Gen-AI developer. What kind of projects are you working on? \\n\\nI'm always interested to hear about what people are building with this technology.  Perhaps we could learn from each other.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 21, 'total_tokens': 83, 'completion_time': 0.112727273, 'prompt_time': 0.00015138, 'queue_time': 0.01427331, 'total_time': 0.112878653}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f7a1e478-76d8-4008-aab9-0c8f05fcc770-0', usage_metadata={'input_tokens': 21, 'output_tokens': 62, 'total_tokens': 83})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi I Am Ajith ,Working As Gen - AI Developer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Ajith, and you work as a Gen-AI Developer!  \\n\\nAs a large language model, I have access to the information we've already exchanged in our conversation. ðŸ˜Š  \\n\\nWhat can I help you with next?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 102, 'total_tokens': 154, 'completion_time': 0.094545455, 'prompt_time': 0.003278167, 'queue_time': 0.011960482, 'total_time': 0.097823622}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a3dba17d-dfd3-4d24-a29c-7ca3fd58ffbb-0', usage_metadata={'input_tokens': 102, 'output_tokens': 52, 'total_tokens': 154})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi I Am Ajith ,Working As Gen - AI Developer\"),\n",
    "    AIMessage(content=\"Hi Ajith!\\n\\nThat's awesome!  It's great to meet another Gen-AI developer. \\n\\nWhat kind of projects are you working on? I'm always interested to hear about what people are building with this technology.  \\n\\nMaybe we could even brainstorm some ideas together sometime!\"),\n",
    "    HumanMessage(content=\"Hey Whats My name What do i do ?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat_1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Ajith! It's great to meet you. \\n\\nBeing a Gen-AI developer is exciting work! What kind of projects are you working on? \\n\\nI'm always eager to learn more about the innovative things people are building with AI. ðŸ˜Š\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi I Am Ajith ,Working As Gen - AI Developer\")],\n",
    "    config=config\n",
    ")\n",
    "res1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ajith, as you introduced yourself!  ðŸ˜„  \\n\\nIs there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's My Name\")],\n",
    "    config=config\n",
    ")\n",
    "res2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\"configurable\":{\"session_id\":\"chat_2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to learn it! ðŸ˜Š\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's My Name\")],\n",
    "    config=config2\n",
    ")\n",
    "res3.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"your are helpful assistent ,Answer all the question with more cretive in tamil \"),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='à®µà®£à®•à¯à®•à®®à¯ Aji ðŸ’™\\n\\nà®Žà®©à®•à¯à®•à¯ à®®à®•à®¿à®´à¯à®šà¯à®šà®¿! à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®‰à®¤à®µà®¿ à®šà¯†à®¯à¯à®¯ à®°à¯Šà®®à¯à®ªà®µà¯‡ à®šà®¨à¯à®¤à¯‹à®šà®®à®¾à®• à®‡à®°à¯à®•à¯à®•à®¿à®±à®¤à¯. \\n\\nà®Žà®¨à¯à®¤ à®•à¯‡à®³à¯à®µà®¿à®•à®³à¯à®•à¯à®•à¯à®®à¯ à®‰à®™à¯à®•à®³à¯ à®µà®¿à®°à¯à®ªà¯à®ªà®®à®¾à®© à®ªà®Ÿà®¿ à®¤à®°à¯ˆà®¯à®¿à®±à®•à¯à®•à®¿à®µà®¿à®Ÿà¯à®™à¯à®•à®³à¯, \\n\\nà®‡à®¯à¯‡à®šà¯à®µà®¿à®©à¯ à®•à®¿à®°à¯à®ªà¯ˆà®¯à®¾à®²à¯ à®‡à®¯à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®Ÿ, à®’à®°à¯ à®‰à®¤à®µà®¿à®¯à®¾à®³à®°à®¾à®• à®Žà®©à¯à®©à¯ˆ à®¨à¯€à®™à¯à®•à®³à¯ à®…à®´à¯ˆà®•à¯à®•à®²à®¾à®®à¯.\\n\\nðŸ˜Š ðŸŒ¸ \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 114, 'prompt_tokens': 33, 'total_tokens': 147, 'completion_time': 0.207272727, 'prompt_time': 0.000329499, 'queue_time': 0.013308608999999999, 'total_time': 0.207602226}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-899aab1f-0179-4040-b6ed-3d2140a1edb5-0', usage_metadata={'input_tokens': 33, 'output_tokens': 114, 'total_tokens': 147})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config3 = {\"configurable\":{\"session_id\":\"chat_3\"}}\n",
    "\n",
    "chain.invoke({\"message\":[HumanMessage(content=\"hi My name is Aji ðŸ’™\")]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I\\'m delighted to assist you!  To help me figure out your name, could you tell me a little about yourself? \\n\\nPerhaps a riddle, a hint about your favorite things, or even a funny story involving your name?\\n\\n\" à®Žà®©à¯ à®ªà¯†à®¯à®°à¯ˆ à®•à®£à¯à®Ÿà¯à®ªà®¿à®Ÿà®¿à®•à¯à®• à®‰à®¤à®µà®¿ à®šà¯†à®¯à¯à®¯ à®µà®¿à®°à¯à®®à¯à®ªà¯à®•à®¿à®±à¯‡à®©à¯! \\nà®‰à®©à¯à®©à¯à®Ÿà¯ˆà®¯ à®ªà¯†à®¯à®°à¯ˆ à®Žà®©à®•à¯à®•à¯ à®¤à¯†à®°à®¿à®µà®¿à®•à¯à®•  à®Žà®©à¯à®© à®šà®¿à®² à®•à¯à®±à®¿à®ªà¯à®ªà¯à®•à®³à¯ˆ à®•à¯Šà®Ÿà¯à®•à¯à®•à®²à®¾à®®à®¾? \\nà®’à®°à¯ à®ªà¯à®¤à®¿à®°à®²à¯, à®‰à®©à¯ à®µà®¿à®°à¯à®ªà¯à®ªà®®à®¾à®© à®ªà¯Šà®°à¯à®Ÿà¯à®•à®³à¯ à®•à¯à®±à®¿à®¤à¯à®¤ à®’à®°à¯ à®•à¯à®±à®¿à®ªà¯à®ªà¯ à®…à®²à¯à®²à®¤à¯  à®‰à®©à¯ à®ªà¯†à®¯à®°à¯ˆ à®‰à®³à¯à®³à®Ÿà®•à¯à®•à®¿à®¯ à®’à®°à¯ à®šà®¿à®°à®¿à®ªà¯à®ªà¯à®•à¯à®•à¯ à®¨à®¿à®±à¯ˆà®¨à¯à®¤ à®•à®¤à¯ˆ à®•à¯‚à®Ÿ à®¨à®²à¯à®²à®¤à¯!\" \\n\\n\\nLet\\'s play a game and unravel the mystery of your name! ðŸ˜Š\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 181, 'prompt_tokens': 33, 'total_tokens': 214, 'completion_time': 0.329090909, 'prompt_time': 0.000340519, 'queue_time': 0.013187799, 'total_time': 0.329431428}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a64621d1-fa3a-41cf-a119-11afb333314b-0', usage_metadata={'input_tokens': 33, 'output_tokens': 181, 'total_tokens': 214})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"message\":[HumanMessage(content=\"What's My Name\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='à®µà®£à®•à¯à®•à®®à¯ à®…à®œà®¿! ðŸ’™ \\n\\nà®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®‰à®¤à®µà¯à®®à¯ à®®à¯†à®©à¯à®ªà¯Šà®°à¯à®³à¯. à®Žà®©à¯à®© à®µà®¿à®©à®¾à®•à¯à®•à®³à¯ à®‡à®°à¯à®•à¯à®•à®¿à®©à¯à®±à®©? ðŸ˜Š \\n\\nà®¨à¯€à®™à¯à®•à®³à¯ à®Žà®¤à¯ˆà®¯à®¾à®µà®¤à¯ à®•à¯‡à®Ÿà¯à®•à®²à®¾à®®à¯. à®¨à®¾à®©à¯ à®Žà®©à¯à®©à¯ˆ à®…à®¤à®¿à®•à®®à®¾à®• à®ªà®¯à®©à¯à®³à¯à®³à®¤à®¾à®•à®µà¯à®®à¯, ì°½ì˜ì ì¸ à®ªà®¤à®¿à®²à¯à®•à®³à¯ˆà®¤à¯ à®¤à®°à¯à®µà®¤à®±à¯à®•à¯ à®Žà®ªà¯à®ªà¯‹à®¤à¯à®®à¯ à®¤à®¯à®¾à®°à®¾à®•à®µà¯à®®à¯ à®µà¯ˆà®¤à¯à®¤à®¿à®°à¯à®•à¯à®•à®¿à®±à¯‡à®©à¯! ðŸ¤© \\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 107, 'prompt_tokens': 33, 'total_tokens': 140, 'completion_time': 0.194545455, 'prompt_time': 0.001616654, 'queue_time': 0.012123774, 'total_time': 0.196162109}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7e2ff73e-742c-4143-b915-eee88d430a8c-0', usage_metadata={'input_tokens': 33, 'output_tokens': 107, 'total_tokens': 140})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({\"message\":[HumanMessage(content=\"hi My name is Aji ðŸ’™\")]},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Aji!  ðŸ’™  I remember!  \\n\\nIs there anything else I can help you with today, Aji?\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 214, 'total_tokens': 245, 'completion_time': 0.056363636, 'prompt_time': 0.008278234, 'queue_time': 0.013257832999999998, 'total_time': 0.06464187}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b0508995-560a-450c-8f19-8011eb1dd4db-0', usage_metadata={'input_tokens': 214, 'output_tokens': 31, 'total_tokens': 245})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({\"message\":[HumanMessage(content=\"what's my name\")]},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"your are helpful assistent ,Answer all the question with best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"message\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='à®‰à®™à¯à®•à®³à¯ à®ªà¯†à®¯à®°à¯ à®…à®œà®¿ ðŸ˜Š  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 152, 'total_tokens': 165, 'completion_time': 0.023636364, 'prompt_time': 0.00504511, 'queue_time': 0.008717318, 'total_time': 0.028681474}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b16ff472-df3e-492a-ba5a-9e933cb0e20a-0', usage_metadata={'input_tokens': 152, 'output_tokens': 13, 'total_tokens': 165})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke({\"message\":[HumanMessage(content=\"what's my name\")],\"language\":\"tamil\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_token=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m GoogleGenerativeAIEmbeddings(model\u001b[38;5;241m=\u001b[39mmodel_name, google_api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Now, you can load the FAISS index\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mChatbot\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mai-chat-bot\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mbackend_ai_chatbot\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43muploads\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mBot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Chatbot\\ai-chat-bot\\backend_ai_chatbot\\chatbot_env\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1188\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[1;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load FAISS index, docstore, and index_to_docstore_id from disk.\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \n\u001b[0;32m   1176\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;124;03m        arbitrary code on your machine.\u001b[39;00m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n\u001b[1;32m-> 1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe de-serialization relies loading a pickle file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickle files can be modified to deliver a malicious payload that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults in execution of arbitrary code on your machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to set `allow_dangerous_deserialization` to `True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable deserialization. If you do this, make sure that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust the source of the data. For example, if you are loading a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile that you created, and know that no one else has modified the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, then this is safe to do. Do not set this to `True` if you are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading a file from an untrusted source (e.g., some random site on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe internet.).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[0;32m   1200\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(folder_path)\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.)."
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Provide the model name or other necessary arguments\n",
    "model_name = \"models/embedding-001\"\n",
    "api_key = \"AIzaSyA3-0m7MQxNzWZJzVyyOCmNlU_Z_q-SWiw\"\n",
    "    \n",
    "    # Create the embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=model_name, google_api_key=api_key)\n",
    "\n",
    "# Now, you can load the FAISS index\n",
    "a = FAISS.load_local(\"D:\\\\Chatbot\\\\ai-chat-bot\\\\backend_ai_chatbot\\\\uploads\\\\csv\\\\index\\\\Bot\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
